{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJoYositrFvgtDlREqsguY"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Decsion Tree and Logistic Regression for Multi classification**"
      ],
      "metadata": {
        "id": "Kfga4RDQr-27"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNzKy-KLoQCT",
        "outputId": "49b501be-d1a5-4a05-db13-06e746e25f68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425345 sha256=c676b6c8d3b360403b5f97ba1fba232e136b081c42f5ba05c9316b8e17dbfb3f\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n"
          ]
        }
      ],
      "source": [
        "# every package has to install each time googlecolab runs jyputernote book.\n",
        "\n",
        "!pip install pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# input the data csv file with the pathpath\n",
        "dataset = spark.read.csv('/content/bezdekIris.data',inferSchema=True, header =True)\\\n",
        ".toDF(\"sep_len\", \"sep_wid\", \"pet_len\", \"pet_wid\", \"label\")\n",
        "dataset.show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7YB4J26sfQD",
        "outputId": "751dad4d-c863-489e-f5ec-8803047dae24"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+-------+-------+-----------+\n",
            "|sep_len|sep_wid|pet_len|pet_wid|      label|\n",
            "+-------+-------+-------+-------+-----------+\n",
            "|    4.9|    3.0|    1.4|    0.2|Iris-setosa|\n",
            "|    4.7|    3.2|    1.3|    0.2|Iris-setosa|\n",
            "|    4.6|    3.1|    1.5|    0.2|Iris-setosa|\n",
            "|    5.0|    3.6|    1.4|    0.2|Iris-setosa|\n",
            "|    5.4|    3.9|    1.7|    0.4|Iris-setosa|\n",
            "+-------+-------+-------+-------+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.select('label').distinct().show(10)\n",
        "dataset.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Tq6Iwi2tMzM",
        "outputId": "d6dbdc65-0cb7-4ed9-955e-92e08b90444d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+\n",
            "|          label|\n",
            "+---------------+\n",
            "| Iris-virginica|\n",
            "|    Iris-setosa|\n",
            "|Iris-versicolor|\n",
            "+---------------+\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "149"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "vector_assembler = VectorAssembler(\\\n",
        "inputCols = [\"sep_len\",\"sep_wid\",\"pet_len\",\"pet_wid\"],\\\n",
        "outputCol = \"features\")\n",
        "df_temp = vector_assembler.transform(dataset)\n",
        "df_temp.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoYm1gjouOtj",
        "outputId": "30c53c6d-a63a-4b1f-e30f-041f84af9a45"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+-------+-------+-----------+-----------------+\n",
            "|sep_len|sep_wid|pet_len|pet_wid|      label|         features|\n",
            "+-------+-------+-------+-------+-----------+-----------------+\n",
            "|    4.9|    3.0|    1.4|    0.2|Iris-setosa|[4.9,3.0,1.4,0.2]|\n",
            "|    4.7|    3.2|    1.3|    0.2|Iris-setosa|[4.7,3.2,1.3,0.2]|\n",
            "|    4.6|    3.1|    1.5|    0.2|Iris-setosa|[4.6,3.1,1.5,0.2]|\n",
            "|    5.0|    3.6|    1.4|    0.2|Iris-setosa|[5.0,3.6,1.4,0.2]|\n",
            "|    5.4|    3.9|    1.7|    0.4|Iris-setosa|[5.4,3.9,1.7,0.4]|\n",
            "|    4.6|    3.4|    1.4|    0.3|Iris-setosa|[4.6,3.4,1.4,0.3]|\n",
            "|    5.0|    3.4|    1.5|    0.2|Iris-setosa|[5.0,3.4,1.5,0.2]|\n",
            "|    4.4|    2.9|    1.4|    0.2|Iris-setosa|[4.4,2.9,1.4,0.2]|\n",
            "|    4.9|    3.1|    1.5|    0.1|Iris-setosa|[4.9,3.1,1.5,0.1]|\n",
            "|    5.4|    3.7|    1.5|    0.2|Iris-setosa|[5.4,3.7,1.5,0.2]|\n",
            "|    4.8|    3.4|    1.6|    0.2|Iris-setosa|[4.8,3.4,1.6,0.2]|\n",
            "|    4.8|    3.0|    1.4|    0.1|Iris-setosa|[4.8,3.0,1.4,0.1]|\n",
            "|    4.3|    3.0|    1.1|    0.1|Iris-setosa|[4.3,3.0,1.1,0.1]|\n",
            "|    5.8|    4.0|    1.2|    0.2|Iris-setosa|[5.8,4.0,1.2,0.2]|\n",
            "|    5.7|    4.4|    1.5|    0.4|Iris-setosa|[5.7,4.4,1.5,0.4]|\n",
            "|    5.4|    3.9|    1.3|    0.4|Iris-setosa|[5.4,3.9,1.3,0.4]|\n",
            "|    5.1|    3.5|    1.4|    0.3|Iris-setosa|[5.1,3.5,1.4,0.3]|\n",
            "|    5.7|    3.8|    1.7|    0.3|Iris-setosa|[5.7,3.8,1.7,0.3]|\n",
            "|    5.1|    3.8|    1.5|    0.3|Iris-setosa|[5.1,3.8,1.5,0.3]|\n",
            "|    5.4|    3.4|    1.7|    0.2|Iris-setosa|[5.4,3.4,1.7,0.2]|\n",
            "+-------+-------+-------+-------+-----------+-----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#remove unnecessary columns:\n",
        "df = df_temp.drop('sep_len','sep_wid','pet_len','pet_wid')\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Word6yYpvjEH",
        "outputId": "b5d70f70-aa11-48bc-a99e-94c6b3b48918"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------------+\n",
            "|      label|         features|\n",
            "+-----------+-----------------+\n",
            "|Iris-setosa|[4.9,3.0,1.4,0.2]|\n",
            "|Iris-setosa|[4.7,3.2,1.3,0.2]|\n",
            "|Iris-setosa|[4.6,3.1,1.5,0.2]|\n",
            "|Iris-setosa|[5.0,3.6,1.4,0.2]|\n",
            "|Iris-setosa|[5.4,3.9,1.7,0.4]|\n",
            "|Iris-setosa|[4.6,3.4,1.4,0.3]|\n",
            "|Iris-setosa|[5.0,3.4,1.5,0.2]|\n",
            "|Iris-setosa|[4.4,2.9,1.4,0.2]|\n",
            "|Iris-setosa|[4.9,3.1,1.5,0.1]|\n",
            "|Iris-setosa|[5.4,3.7,1.5,0.2]|\n",
            "|Iris-setosa|[4.8,3.4,1.6,0.2]|\n",
            "|Iris-setosa|[4.8,3.0,1.4,0.1]|\n",
            "|Iris-setosa|[4.3,3.0,1.1,0.1]|\n",
            "|Iris-setosa|[5.8,4.0,1.2,0.2]|\n",
            "|Iris-setosa|[5.7,4.4,1.5,0.4]|\n",
            "|Iris-setosa|[5.4,3.9,1.3,0.4]|\n",
            "|Iris-setosa|[5.1,3.5,1.4,0.3]|\n",
            "|Iris-setosa|[5.7,3.8,1.7,0.3]|\n",
            "|Iris-setosa|[5.1,3.8,1.5,0.3]|\n",
            "|Iris-setosa|[5.4,3.4,1.7,0.2]|\n",
            "+-----------+-----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we should index labels, i.e., convert textual representation to a numeric\n",
        "List item\n",
        "List item\n",
        "one with the help of StringIndexer. To do this, execute the following commands:"
      ],
      "metadata": {
        "id": "nUmjJxpZxbxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "l_indexer = StringIndexer(inputCol=\"label\", outputCol=\"labelIndex\")\n",
        "df = l_indexer.fit(df).transform(df)"
      ],
      "metadata": {
        "id": "nCGdolgCwBgX"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.select('label','labelIndex').distinct().show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-Zb9oKVxfmX",
        "outputId": "7e19275b-5420-4e55-e2a6-60c5f670d323"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+----------+\n",
            "|          label|labelIndex|\n",
            "+---------------+----------+\n",
            "|Iris-versicolor|       0.0|\n",
            "| Iris-virginica|       1.0|\n",
            "|    Iris-setosa|       2.0|\n",
            "+---------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Divide the data into train and test set(30% for test)"
      ],
      "metadata": {
        "id": "fGbB83JPxvLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(trainingData, testData) = df.randomSplit([0.7, 0.3])"
      ],
      "metadata": {
        "id": "uHKblv4qxtow"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multi Classification using Decsion Tree"
      ],
      "metadata": {
        "id": "3C6EDQmBx7dY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "dt = DecisionTreeClassifier(labelCol=\"labelIndex\", featuresCol=\"features\",impurity='entropy', maxDepth=4,seed=1234)\n",
        "model = dt.fit(trainingData)\n",
        "predictions = model.transform(testData)"
      ],
      "metadata": {
        "id": "R8xuSyMzx5QQ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To estimate the accuracy of the prediction, the test error should be computed :"
      ],
      "metadata": {
        "id": "0WxrdSlzyQ4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = MulticlassClassificationEvaluator(\\\n",
        "labelCol=\"labelIndex\", predictionCol=\"prediction\",\\\n",
        "metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(\"Test accuracy =  \" , accuracy)\n",
        "print(model.toDebugString)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfE3ebgDyR04",
        "outputId": "2093932a-38f7-4bd5-eb2c-8381fa2c154a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy =   0.9347826086956522\n",
            "DecisionTreeClassificationModel: uid=DecisionTreeClassifier_ec566bc58ec8, depth=4, numNodes=11, numClasses=3, numFeatures=4\n",
            "  If (feature 2 <= 2.45)\n",
            "   Predict: 2.0\n",
            "  Else (feature 2 > 2.45)\n",
            "   If (feature 3 <= 1.75)\n",
            "    If (feature 2 <= 4.95)\n",
            "     If (feature 0 <= 4.95)\n",
            "      Predict: 1.0\n",
            "     Else (feature 0 > 4.95)\n",
            "      Predict: 0.0\n",
            "    Else (feature 2 > 4.95)\n",
            "     If (feature 3 <= 1.65)\n",
            "      Predict: 1.0\n",
            "     Else (feature 3 > 1.65)\n",
            "      Predict: 0.0\n",
            "   Else (feature 3 > 1.75)\n",
            "    Predict: 1.0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multiclassification using Logisitc Regression"
      ],
      "metadata": {
        "id": "dP3lAeCDy3qx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# this is code for multiple classification using logistic Regression\n",
        "from pyspark.ml.classification import OneVsRest\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "train, test = df.randomSplit([0.7, 0.3], seed = 2018)\n",
        "lr = LogisticRegression(maxIter=100, \\\n",
        "\n",
        "                        featuresCol=\"features\", \\\n",
        "\n",
        "                        labelCol='labelIndex')\n",
        "ovr = OneVsRest(classifier=lr, \\\n",
        "                labelCol='labelIndex', \\\n",
        "                featuresCol='features')\n",
        "#from pyspark.ml import Pipeline\n",
        "#pipeline_ovr = Pipeline(stages=[vecAssembler, stdScaler, ovr])\n",
        "#pipelineModel_ovr = pipeline_ovr.fit(trainDF)\n",
        "\n",
        "ovrModel = ovr.fit(train)\n",
        "predictionsovr = ovrModel.transform(test)"
      ],
      "metadata": {
        "id": "QGQTiq-5yo1x"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = MulticlassClassificationEvaluator(\\\n",
        "labelCol=\"labelIndex\", predictionCol=\"prediction\",\\\n",
        "metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictionsovr)\n",
        "print(\"Test accuracy =  \" , accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNVBCgsUzBVQ",
        "outputId": "5c9bca6e-8a9d-4483-ac12-dc2d34b5d149"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy =   0.9361702127659575\n"
          ]
        }
      ]
    }
  ]
}